{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Scientific Data to Binary Files\n",
    "\n",
    "Text files are nice for small files, but most scientific data is way too large and complex to be easy to work with as text.  So, we need more flexibility, and for that we use binary files, which allow us to store data however we want.  \n",
    "\n",
    "But as the superhero CodeMan always says, \"With great flexibility come great complexity\".  In this section, we'll get a sense of how libraries that help us store scientific data into binary files in a way that gives us both flexibility and simplicity!\n",
    "\n",
    "Particularly, we'll end up looking at HDF5 ('.h5', '.hdf', '.hdf5) files, which are used as the core file format for a wide variety of popular data formats, and which works as the basic for the NIX files we'll be working with later on to store complex neuroscience data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing Numpy arrays directly to a binary File\n",
    "\n",
    "Can we create our own binary files?  Of course!  Below, we'll make numpy arrays and play around with serializing the numpy \n",
    "\n",
    "| **Code** | **Description ** |\n",
    "| :-- | :-- |\n",
    "| **`f = open('data.dat', 'wb')`** | Open a new file file, ready for writing binary data |\n",
    "| **`f = open('data.dat', 'rb')`** | Open a new file file, ready for reading binary data |\n",
    "| **`f.close()`** | Close the file linked to the file object and release it to the operating system |\n",
    "| **`x = np.arange(10).astype(np.uint8)`** | Create an array `x` of 10 values (0-9) where each is stored as unsigned, 8-bit integers |\n",
    "| **`data_bytes = array.tobytes()`** |  Serialize a numpy array `array` to a binary string `data_bytes` |\n",
    "| **`array = np.frombuffer(data_bytes, dtype=np.uint8)`** | Deserialize a binary string into a numpy array interpreted as being made of unsigned 8-bit integers. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Write 5 16-bit integers to the binary file `x1.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5).astype(np.int16)\n",
    "f = open('x1.dat', 'wb')\n",
    "f.write(x.tobytes())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 8 8-bit, unsigned integers to the binary file `x2.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up the `x2.dat` file in your text editor (you'll have to insist that it's readable as text, even though it's really not).  What does the data look like, is the data recognizable?  More importantly, how many characters are there in the file, does this seem like the right number of bytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 8 64-bit, unsigned integers to the binary file `x3.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up the `x3.dat` file in your text editor (you'll have to insist that it's readable as text, even though it's really not).  What does the data look like, is the data recognizable?  More importantly, does it seem like it's got **more** data than the `x2.dat` file?  It should take up 8x as much space, because 64 bits is 8 times more space than 8 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `x2.dat` file back as a Numpy array, and make sure it was read back correctly  (note: you'll have to tell numpy how the data should be read, most-commonly in the `np.frombuffer()` function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `x3.dat` file back as a Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Numpy Arrays to NPY and NPZ Files using Numpy\n",
    "\n",
    "It's challenging to read in data files when you don't know ahead of time how the data is actually stored.  Numpy provides two formats, \".npy\" and \".npz\" that make reading data \n",
    "into Numpy easier by putting the data's format directly into the file itself.  This takes up just a little more space, but it makes the data way easier to work with!\n",
    "\n",
    "| **Code** | **Description ** |\n",
    "| :-- | :-- |\n",
    "| **`np.random.random(size=100).astype(np.float32)`** | Create 100 random float32 values between 0 and 1 |\n",
    "| **`np.random.randint(1, 10, size=20).astype(np.uint8)`** | Create 20 random 8-bit, unsigned integers between 0 and 10 |\n",
    "| **`np.save('data.npy', data)`** | Save the `data` array to the `data.npy` file |\n",
    "| **`np.savez('data.npz', x=x1, y=y1)`** | Save the `x1` and `y1` arrays as `x` and `y` variables in the `data.npz` file |\n",
    "| **`data = np.load('data.npy')`** | Load the `data` array from the `data.npy` file |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Create 10 random 16-bit floating numbers and save them to `x1.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=10).astype(np.float16)\n",
    "np.save('x1.npy', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Load the data in `x1.npy`.  Was it saved correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5913, 0.782 , 0.3926, 0.8516, 0.7036, 0.4297, 0.424 , 0.9927,\n",
       "       0.8354, 0.2898], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('x1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 15 random 32-bit integers between 100 and 200 and save them to `x2.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in `x2.npy`.  was it saved correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a text editor, take a look at how the `x2.npy` file was saved. (Note: you may have to \"insist\" that the data can be read in the text editor). Can you find where the data's schema is stored in the file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save both an array of times (float64) and an array of voltages (uint16) to `ephys.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a text editor, take a look at how the `ephys.npz` file was saved. (Note: you may have to \"insist\" that the data can be read in the text editor). Can you find where the data's schema is stored in the file?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the volts from `ephys.npz`.  Was it saved correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Mixed-Type, Labelled, Data and Metadata to HDF5 Files using h5py\n",
    "\n",
    "HDF5 files have a lot more features:\n",
    "  - They are highly cross-platform and work with a wide variety of tools\n",
    "  - They can store many different datasets in a single file (or even in multiple linked files)\n",
    "  - They can store metadata alonside the data\n",
    "  - They let you store data hierarchically, making a nice dict-like nested organization for your data\n",
    "  - They can compress your data.\n",
    "  - They let you work with data that is larger than memory, making it easy to read in only the data that you need.\n",
    "\n",
    "\n",
    "So many features!  Here, we'll get a basic senses of how they work by using the `h5py` library, which gives us a dict-like, Numpy-native interface to HDF5 files and is used internally by many popular Python frameworks.\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "| **`f = h5py.File('filename.h5', 'w')`** | Open an h5py file object for writing |\n",
    "| **`f.close()`** | Closes the h5py file and releases the linked file back to the operating system. |\n",
    "| **`f.create_dataset('temp', data=x)`** | Write an array called 'temp' with the data in the numy array `x` into the HDF5 file |\n",
    "| **`f.create_dataset('data/temp', data=x)`** | Write an array called 'temp' in the folder called \"data\" with the data in the numy array `x` into the HDF5 file |\n",
    "| **`f.attrs['name'] = 'Session 1'`** | Set an attribute as metadata onto the root group of the HDF5 file -- this works like a normal Python dictionary |\n",
    "| **`f['x'].attrs['id'] = 'ABC'`** | Set an attribute as metadata onto the 'x' node of the HDF file |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install h5py numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Write an HDF5 File called `temp.h5` with the following schema:\n",
    "```\n",
    "root/\n",
    "└── temp: uint16, 1000 x 1  (temperature measurements over time)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(15, 22, size=(1000,1)).astype(np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('temp.h5', 'w') as f:\n",
    "    f.create_dataset('temp', data=temp)\n",
    "    f['temp'].attrs.update({\n",
    "        'description': 'Temperature measurements over time'\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an HDF5 File called `ephys.h5` with the following schema and descriptions:\n",
    "\n",
    "```\n",
    "root/\n",
    "├── time: float32, 1 x 1000 (trial time, in seconds)\n",
    "├── voltage: int16, 4 x 1000 (voltage measurements for each recording channel)\n",
    "└──chan_names: S, 4 (channel names for each recording channel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0, 3, 1000).astype(np.float32)\n",
    "voltage = np.random.normal(1, 1, size=(4, 1000)).astype(np.float32)\n",
    "chan_names = ['CH01', 'CH02', 'CH03', 'CH05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an HDF5 File called `motion_tracking.h5` with the following schema (feel free to skip the descriptions this time):\n",
    "```\n",
    "root/\n",
    "├── session_date: str\n",
    "├── subject_id: str\n",
    "├── camera: \n",
    "│   ├── black_noise_image: uint16, 640 x 640 x 3 (reference image taken with lights out)\n",
    "│   ├── image_width: uint16\n",
    "│   ├── image_height: uint16\n",
    "│   ├── shutter_speed: uint16\n",
    "│   └── aperture: float32\n",
    "│\n",
    "└── motion_tracking: \n",
    "    ├── time: uint32 1 x 3000 (session time, in milliseconds)\n",
    "    ├── rb_pos: float32  2 x 3 x 3000 (XYZ coordinates of the center of each tracked rigid body)\n",
    "    ├── rb_rot: float32  2 x 3 x 3000 (XYZ Euler rotations of each tracked rigid body)\n",
    "    ├── xyz_names: str 1 x 3 (The spatial coordinate names)\n",
    "    └── rb_names: str 1 x 2 (The name of each rigid body)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_date = '2024-04-22'\n",
    "subject_id = 'AD11'\n",
    "camera_black_noise_im = np.random.randint(0, 30, size=(640, 640)).astype(np.uint16)\n",
    "im_width = 640\n",
    "im_height = 640\n",
    "shutter_speed = 800\n",
    "aperture = 2.8\n",
    "motion_time = (np.arange(0, 1000, step=1/shutter_speed)[:3000] * 1000).astype(np.uint32)\n",
    "rb_pos = np.random.random(size=(2, 3, 3000)).astype(np.float32)\n",
    "rb_rot = np.random.random(size=(2, 3, 3000)).astype(np.float32)\n",
    "xyz_names = ['X', 'Y', 'Z']\n",
    "rb_names = ['head', 'tail_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from HDF5 Files\n",
    "\n",
    "| **Code** | **Description** |\n",
    "| :-- | :-- |\n",
    "| **`f = h5py.File('file.h5')`** | Opens an h5py file object for reading |\n",
    "| **`f.close()`** | Closes the h5py file and releases the linked file back to the operating system. |\n",
    "| **`f.keys()`** | See a list of datasets and groups at the root node |\n",
    "| **`f.attrs`** | Get the dict-like attributes at the root node |\n",
    "| **`f.attrs['a']']`** | Get the 'a' attribute at the root node  |\n",
    "| **`f['x'][:]`** | Read in the 'x' dataset as a numpy array |\n",
    "| **`f['x'][5:20]`** | Read in a slice of the 'x' dataset as a numpy array |\n",
    "| **`f['x'].keys()`** | See a list of datasets and groups at the 'x' node |\n",
    "| **`f['folder']['x']`** | Get tthe 'x' dataset in the 'folder' group |\n",
    "| **`f['folder/x']`** | (Alternative Syntax) Ge tthe 'x' dataset in the 'folder' group |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: From the temperature file, read in only the last 5 temperature measurements as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16],\n",
       "       [21],\n",
       "       [21],\n",
       "       [16],\n",
       "       [17]], dtype=uint16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('temp.h5')\n",
    "temp = f['temp'][-5:, :]\n",
    "f.close()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ephys file, read in the first 10 voltage measurements as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the ephys file, get the name of the second recording channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ephys file, get the description of the voltage dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the motion tracking file, get the all the XYZ positions of the first rigid body during the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the motion tracking file, get the caemra's shutter speed during the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andani_d1_morning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
